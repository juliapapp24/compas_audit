{"cells":[{"cell_type":"markdown","metadata":{"id":"4jzZreWrixLw"},"source":["# Assignment 1: Algorithmic Fairness Definitions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EeP6Crc-7OqT"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"]}],"source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import metrics"]},{"cell_type":"markdown","metadata":{"id":"WozpzTb87OqV"},"source":["This component of the assignment derives in part, with thanks and permission, from an [assignment](https://web.stanford.edu/class/cs182/assignments/AlgorithmicDecisionMaking.zip) in Stanford's CS182: Ethics, Public Policy, and Technological Change. Their assignment, in turn, is based on the journalistic organization ProPublica's [analysis](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) of a criminal risk prediction algorithm which we discussed in the algorithmic fairness lecture. Here, you will be assessing how a classifier designed to predict recidivism -- that is, whether someone will commit a crime in the future -- performs in terms of algorithmic fairness metrics."]},{"cell_type":"markdown","metadata":{"id":"sYAusEYY7OqV"},"source":["## Problem 1: Loading the data (5 points)"]},{"cell_type":"markdown","metadata":{"id":"QfLjJqPj7OqW"},"source":["We have split the data for you into a train set (`recidivism-training-data.csv`) and test set (`recidivism-testing-data.csv`). You will be training the model on the train set and evaluating model predictions on the test set."]},{"cell_type":"markdown","metadata":{"id":"vj6P51P87OqW","tags":[]},"source":["1a. Read in the train and test sets. Display the first 10 rows of the data. (4 points)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"lzE-3bb_7OqX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Juvenile felony count = 0</th>\n","      <th>Juvenile felony count = 1</th>\n","      <th>Juvenile felony count = 2</th>\n","      <th>Juvenile felony count &gt;= 3</th>\n","      <th>Juvenile misdemeanor count = 0</th>\n","      <th>Juvenile misdemeanor count = 1</th>\n","      <th>Juvenile misdemeanor count = 2</th>\n","      <th>Juvenile misdemeanor count &gt;= 3</th>\n","      <th>Juvenile other offense count = 0</th>\n","      <th>Juvenile other offense count = 1</th>\n","      <th>...</th>\n","      <th>Age &gt; 45</th>\n","      <th>Gender = Female</th>\n","      <th>Gender = Male</th>\n","      <th>Race = Other</th>\n","      <th>Race = Asian</th>\n","      <th>Race = Native American</th>\n","      <th>Race = Caucasian</th>\n","      <th>Race = Hispanic</th>\n","      <th>Race = African American</th>\n","      <th>recidivism_outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 42 columns</p>\n","</div>"],"text/plain":["   Juvenile felony count = 0  Juvenile felony count = 1  \\\n","0                          1                          0   \n","1                          1                          0   \n","2                          1                          0   \n","3                          1                          0   \n","4                          1                          0   \n","5                          1                          0   \n","6                          1                          0   \n","7                          1                          0   \n","8                          1                          0   \n","9                          1                          0   \n","\n","   Juvenile felony count = 2  Juvenile felony count >= 3  \\\n","0                          0                           0   \n","1                          0                           0   \n","2                          0                           0   \n","3                          0                           0   \n","4                          0                           0   \n","5                          0                           0   \n","6                          0                           0   \n","7                          0                           0   \n","8                          0                           0   \n","9                          0                           0   \n","\n","   Juvenile misdemeanor count = 0  Juvenile misdemeanor count = 1  \\\n","0                               1                               0   \n","1                               1                               0   \n","2                               1                               0   \n","3                               1                               0   \n","4                               1                               0   \n","5                               1                               0   \n","6                               1                               0   \n","7                               1                               0   \n","8                               1                               0   \n","9                               0                               1   \n","\n","   Juvenile misdemeanor count = 2  Juvenile misdemeanor count >= 3  \\\n","0                               0                                0   \n","1                               0                                0   \n","2                               0                                0   \n","3                               0                                0   \n","4                               0                                0   \n","5                               0                                0   \n","6                               0                                0   \n","7                               0                                0   \n","8                               0                                0   \n","9                               0                                0   \n","\n","   Juvenile other offense count = 0  Juvenile other offense count = 1  ...  \\\n","0                                 1                                 0  ...   \n","1                                 1                                 0  ...   \n","2                                 1                                 0  ...   \n","3                                 0                                 1  ...   \n","4                                 1                                 0  ...   \n","5                                 1                                 0  ...   \n","6                                 1                                 0  ...   \n","7                                 1                                 0  ...   \n","8                                 1                                 0  ...   \n","9                                 1                                 0  ...   \n","\n","   Age > 45  Gender = Female  Gender = Male  Race = Other  Race = Asian  \\\n","0         0                0              1             0             0   \n","1         0                1              0             0             0   \n","2         0                0              1             0             0   \n","3         0                0              1             0             0   \n","4         0                0              1             0             0   \n","5         0                0              1             1             0   \n","6         0                1              0             0             0   \n","7         1                1              0             0             0   \n","8         0                0              1             0             0   \n","9         0                0              1             0             0   \n","\n","   Race = Native American  Race = Caucasian  Race = Hispanic  \\\n","0                       0                 0                0   \n","1                       0                 0                0   \n","2                       0                 1                0   \n","3                       0                 0                0   \n","4                       0                 0                0   \n","5                       0                 0                0   \n","6                       0                 0                1   \n","7                       0                 0                0   \n","8                       0                 0                0   \n","9                       0                 0                0   \n","\n","   Race = African American  recidivism_outcome  \n","0                        1                   0  \n","1                        1                   0  \n","2                        0                   0  \n","3                        1                   1  \n","4                        1                   1  \n","5                        0                   0  \n","6                        0                   1  \n","7                        1                   1  \n","8                        1                   0  \n","9                        1                   1  \n","\n","[10 rows x 42 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["training_data = pd.read_csv(\"recidivism-testing-data.csv\")\n","training_data.head(10)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"FnQkf9zf7OqX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Juvenile felony count = 0</th>\n","      <th>Juvenile felony count = 1</th>\n","      <th>Juvenile felony count = 2</th>\n","      <th>Juvenile felony count &gt;= 3</th>\n","      <th>Juvenile misdemeanor count = 0</th>\n","      <th>Juvenile misdemeanor count = 1</th>\n","      <th>Juvenile misdemeanor count = 2</th>\n","      <th>Juvenile misdemeanor count &gt;= 3</th>\n","      <th>Juvenile other offense count = 0</th>\n","      <th>Juvenile other offense count = 1</th>\n","      <th>...</th>\n","      <th>Age &gt; 45</th>\n","      <th>Gender = Female</th>\n","      <th>Gender = Male</th>\n","      <th>Race = Other</th>\n","      <th>Race = Asian</th>\n","      <th>Race = Native American</th>\n","      <th>Race = Caucasian</th>\n","      <th>Race = Hispanic</th>\n","      <th>Race = African American</th>\n","      <th>recidivism_outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 42 columns</p>\n","</div>"],"text/plain":["   Juvenile felony count = 0  Juvenile felony count = 1  \\\n","0                          1                          0   \n","1                          1                          0   \n","2                          1                          0   \n","3                          1                          0   \n","4                          1                          0   \n","5                          1                          0   \n","6                          1                          0   \n","7                          1                          0   \n","8                          1                          0   \n","9                          1                          0   \n","\n","   Juvenile felony count = 2  Juvenile felony count >= 3  \\\n","0                          0                           0   \n","1                          0                           0   \n","2                          0                           0   \n","3                          0                           0   \n","4                          0                           0   \n","5                          0                           0   \n","6                          0                           0   \n","7                          0                           0   \n","8                          0                           0   \n","9                          0                           0   \n","\n","   Juvenile misdemeanor count = 0  Juvenile misdemeanor count = 1  \\\n","0                               1                               0   \n","1                               1                               0   \n","2                               1                               0   \n","3                               1                               0   \n","4                               1                               0   \n","5                               1                               0   \n","6                               1                               0   \n","7                               1                               0   \n","8                               1                               0   \n","9                               0                               1   \n","\n","   Juvenile misdemeanor count = 2  Juvenile misdemeanor count >= 3  \\\n","0                               0                                0   \n","1                               0                                0   \n","2                               0                                0   \n","3                               0                                0   \n","4                               0                                0   \n","5                               0                                0   \n","6                               0                                0   \n","7                               0                                0   \n","8                               0                                0   \n","9                               0                                0   \n","\n","   Juvenile other offense count = 0  Juvenile other offense count = 1  ...  \\\n","0                                 1                                 0  ...   \n","1                                 1                                 0  ...   \n","2                                 1                                 0  ...   \n","3                                 0                                 1  ...   \n","4                                 1                                 0  ...   \n","5                                 1                                 0  ...   \n","6                                 1                                 0  ...   \n","7                                 1                                 0  ...   \n","8                                 1                                 0  ...   \n","9                                 1                                 0  ...   \n","\n","   Age > 45  Gender = Female  Gender = Male  Race = Other  Race = Asian  \\\n","0         0                0              1             0             0   \n","1         0                1              0             0             0   \n","2         0                0              1             0             0   \n","3         0                0              1             0             0   \n","4         0                0              1             0             0   \n","5         0                0              1             1             0   \n","6         0                1              0             0             0   \n","7         1                1              0             0             0   \n","8         0                0              1             0             0   \n","9         0                0              1             0             0   \n","\n","   Race = Native American  Race = Caucasian  Race = Hispanic  \\\n","0                       0                 0                0   \n","1                       0                 0                0   \n","2                       0                 1                0   \n","3                       0                 0                0   \n","4                       0                 0                0   \n","5                       0                 0                0   \n","6                       0                 0                1   \n","7                       0                 0                0   \n","8                       0                 0                0   \n","9                       0                 0                0   \n","\n","   Race = African American  recidivism_outcome  \n","0                        1                   0  \n","1                        1                   0  \n","2                        0                   0  \n","3                        1                   1  \n","4                        1                   1  \n","5                        0                   0  \n","6                        0                   1  \n","7                        1                   1  \n","8                        1                   0  \n","9                        1                   1  \n","\n","[10 rows x 42 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["testing_data = pd.read_csv(\"recidivism-testing-data.csv\")\n","testing_data.head(10)"]},{"cell_type":"markdown","metadata":{"id":"w_0Y3zWC7OqY"},"source":["1b. Read the data documentation in the `Algorithmic Fairness Data Documentation` file. What are the possible values of the `Race` variable in the dataset? (1 point)"]},{"cell_type":"markdown","metadata":{"id":"r3FVRqSt7OqZ"},"source":["The specificied race can be one of the following:\n","- Asian\n","- Native American\n","- Caucasian (or white)\n","- Hispanic\n","- African-American (or “Black”)\n","- Other (none of the races above)\n","\n","This means that there is a one-hot vector for the person's race, and it is the value 1 for their one selected race, and 0 for the other boxes."]},{"cell_type":"markdown","metadata":{"id":"wAllbD2S7OqZ"},"source":["## Problem 2: Predicting Recidivism with a Full Logistic Regression (20 points)"]},{"cell_type":"markdown","metadata":{"id":"YNKxlUUMUMSL"},"source":["Now you will use the train set to train a logistic regression model using `sklearn.linear_model.LogisticRegression`. To train a logistic regression model on features X to predict outcome y, you can use the command:\n","\n","`LogisticRegression(penalty='none').fit(X, y)`\n","\n","You will have to replace X and y with the data you actually want to use. [Here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) is the documentation on logistic regression. Use the \"recidivism_outcome\" column as the variable you are trying to predict (y).\n","\n","Then, we will ask you to report model performance metrics. Use the test set to compute those quantities. You could take a look at helpful functions from the [scikit-learn metrics module](https://scikit-learn.org/stable/modules/model_evaluation.html), imported at the beginning of the assignment as `metrics`."]},{"cell_type":"markdown","metadata":{"id":"dqFgXUqK7Oqa"},"source":["2a. Train a logistic regression model using all features (except `recidivism_outcome`) as input features X. (5 points)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nZ1EYyky2XGn"},"outputs":[],"source":["train_input_features = training_data.drop(columns = \"recidivism_outcome\")\n","train_output_feature = training_data[\"recidivism_outcome\"]\n","\n","logistic_regression_model = LogisticRegression(penalty='none', max_iter=1000000).fit(train_input_features, train_output_feature)"]},{"cell_type":"markdown","metadata":{"id":"Z_KdiAkw7Oqb"},"source":["2b. Predict recidivism for the test set. Display the first 10 predictions. (1 point)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bfvt5WUk7Oqb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test preditctions: \n","[1 0 1 1 0 0 0 0 0 1]\n","Test actual: \n","0    0\n","1    0\n","2    0\n","3    1\n","4    1\n","5    0\n","6    1\n","7    1\n","8    0\n","9    1\n","Name: recidivism_outcome, dtype: int64\n"]}],"source":["test_input_features = testing_data.drop(columns=[\"recidivism_outcome\"])\n","test_predictions = logistic_regression_model.predict(test_input_features)\n","test_actual = testing_data[\"recidivism_outcome\"]\n","\n","print(\"Test preditctions: \")\n","print(test_predictions[:10])\n","print(\"Test actual: \")\n","print(testing_data[\"recidivism_outcome\"][:10])"]},{"cell_type":"markdown","metadata":{"id":"FMraWqT27Oqb"},"source":["2c. Report your model's AUC (i) for all defendants, (ii) for white defendants, and (iii) for Black defendants. Report the values with 4 decimal points. (1 point)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5h0R0JZX7Oqc"},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants accuracy: 0.6774\n","Black defendants accuracy: 0.6625\n","White defendants accuracy: 0.6895\n"]}],"source":["def get_accuracy(predictions, actual):\n","    return round((predictions == actual).mean(), 4)\n","\n","def print_accuracy(data, predictions, actual, label):\n","    acc = get_accuracy(predictions, actual)\n","    print(f\"{label} defendants accuracy: {acc}\")\n","\n","all_defendants_predictions = logistic_regression_model.predict(testing_data.drop(columns=['recidivism_outcome']))\n","black_defendants_predictions = logistic_regression_model.predict(testing_data.loc[testing_data[\"Race = African American\"] == 1].drop(columns=['recidivism_outcome']))\n","white_defendants_predictions = logistic_regression_model.predict(testing_data.loc[testing_data[\"Race = Caucasian\"] == 1].drop(columns=['recidivism_outcome']))\n","\n","print_accuracy(testing_data, all_defendants_predictions, testing_data[\"recidivism_outcome\"], \"All\")\n","print_accuracy(testing_data.loc[testing_data[\"Race = African American\"] == 1], black_defendants_predictions, testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"], \"Black\")\n","print_accuracy(testing_data.loc[testing_data[\"Race = Caucasian\"] == 1], white_defendants_predictions, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"], \"White\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oNSmG6jR7Oqc"},"source":["2d. Report your model's false positive rate (i) for all defendants, (ii) for white defendants, and (iii) for Black defendants. Report the values with 4 decimal points. (1 point)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"PW1N8jwR7Oqc"},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants false positive rate: 0.2563\n","Black defendants false positive rate: 0.3578\n","White defendants false positive rate: 0.183\n"]}],"source":["def get_false_positive_rate(predictions, actual):\n","    false_positives = ((predictions == 1) & (actual == 0)).sum()\n","    total_negatives = (actual == 0).sum()\n","    return round(false_positives / total_negatives, 4)\n","\n","all_defendants_predictions = logistic_regression_model.predict(testing_data.drop(columns=['recidivism_outcome']))\n","black_defendants_predictions = logistic_regression_model.predict(testing_data.loc[testing_data[\"Race = African American\"] == 1].drop(columns=['recidivism_outcome']))\n","white_defendants_predictions = logistic_regression_model.predict(testing_data.loc[testing_data[\"Race = Caucasian\"] == 1].drop(columns=['recidivism_outcome']))\n","\n","fpr_all = get_false_positive_rate(all_defendants_predictions, testing_data[\"recidivism_outcome\"])\n","fpr_black = get_false_positive_rate(black_defendants_predictions, testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"])\n","fpr_white = get_false_positive_rate(white_defendants_predictions, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"])\n","\n","print(\"All defendants false positive rate: \" + str(fpr_all))\n","print(\"Black defendants false positive rate: \" + str(fpr_black))\n","print(\"White defendants false positive rate: \" + str(fpr_white))"]},{"cell_type":"markdown","metadata":{"id":"1juBJxnl7Oqd"},"source":["2e. Report your model's false negative rate (i) for all defendants, (ii) for white defendants, and (iii) for Black defendants. Report the values with 4 decimal points. (1 point)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"IYg1Mmjr7Oqd"},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants false negative rate: 0.4048\n","Black defendants false negative rate: 0.3181\n","White defendants false negative rate: 0.5124\n"]}],"source":["def get_false_negative_rate(predictions, actual):\n","    false_negatives = ((predictions == 0) & (actual == 1)).sum()\n","    total_positives = (actual == 1).sum()\n","    return round(false_negatives / total_positives, 4)\n","\n","fnr_all = get_false_negative_rate(all_defendants_predictions, testing_data[\"recidivism_outcome\"])\n","fnr_black = get_false_negative_rate(black_defendants_predictions, testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"])\n","fnr_white = get_false_negative_rate(white_defendants_predictions, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"])\n","\n","print(\"All defendants false negative rate:\", fnr_all)\n","print(\"Black defendants false negative rate:\", fnr_black)\n","print(\"White defendants false negative rate:\", fnr_white)\n"]},{"cell_type":"markdown","metadata":{"id":"x7Odx7Kb7Oqd"},"source":["2f. Report the fraction of defendants classified positive by your model (i) for all defendants, (ii) for white defendants, and (iii) for Black defendants. Report the values with 4 decimal points. (1 point)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"mti4o1MO7Oqe"},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants predicted positive rate: 0.4076\n","Black defendants predicted positive rate: 0.5233\n","White defendants predicted positive rate: 0.301\n"]}],"source":["def get_predicted_positive(predictions, actual):\n","    tp = ((predictions == 1) & (actual == 1)).sum()\n","    fp = ((predictions == 1) & (actual == 0)).sum()\n","    tn = ((predictions == 0) & (actual == 0)).sum()\n","    fn = ((predictions == 0) & (actual == 1)).sum()\n","\n","    predicted_positive_rate = (tp + fp) / (tp + fn + fp + tn)\n","    return round(predicted_positive_rate, 4)\n","\n","predicted_positive_all = get_predicted_positive(all_defendants_predictions, testing_data[\"recidivism_outcome\"])\n","predicted_positive_black = get_predicted_positive(black_defendants_predictions, testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"])\n","predicted_positive_white = get_predicted_positive(white_defendants_predictions, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"])\n","\n","print(\"All defendants predicted positive rate:\", predicted_positive_all)\n","print(\"Black defendants predicted positive rate:\", predicted_positive_black)\n","print(\"White defendants predicted positive rate:\", predicted_positive_white)"]},{"cell_type":"markdown","metadata":{"id":"Hj_-3ze7Wy_y"},"source":["2g. In at least 5 sentences, describe what you observe, and any algorithmic fairness concerns it raises, making reference to specific algorithmic fairness concepts discussed in class and using quantitative evidence from 2c-f. Do you believe this algorithm is fair enough to be deployed in practice? Why or why not? (10 points)"]},{"cell_type":"markdown","metadata":{},"source":["The above trained algorithm raises a few algorithmic fairness concerns. \n","\n","First, it does not satisfy the predictive equality (also known as equalized odds) measurment, since Black defendants who do not reoffend are more likely than white defendant that do not reoffend to be predicted to be someone who will reoffend. This is evident in 2.d, where we show that this model has a false positive rate of 0.3578 for Black defendants and a false positive rate of 0.183 for white defendants, meaning that about twice as many Black defendants are falsely classified as someone who will reoffend. It is also evident that this model does not satisfy the predictive equality measurement when examining the false positive rates, since we can see in 2.e that Black defendants who do reoffend will only be predicted that they won't reoffend at a rate of 0.3181, whereas white defendants that do reoffend will be classifed as someone that won't reoffend at a rate of 0.5124. This means that since the false positive rates and false negative rates do not match for all races, it does not satisfy the predictive equality principle. \n","\n","Second, it also does not satisfy the statistical parity principle, since Black defendants are more likely to be predicted to reoffend than white defendants (based on 2.f, Black defendants predicted to reoffend rate being 0.5233, compared to white defendants predicted to reoffend rate being 0.3871). \n","\n","To check if the model satisfies demographic balance principle, we can write the following program:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants positive rate: 0.4464\n","Black defendants positive rate: 0.5108\n","White defendants positive rate: 0.3871\n"]}],"source":["actual_reoffend_all = testing_data.loc[testing_data[\"recidivism_outcome\"] == 1]\n","actual_reoffend_black = testing_data.loc[(testing_data[\"Race = African American\"] == 1) & (testing_data[\"recidivism_outcome\"] == 1)]\n","actual_reoffend_white = testing_data.loc[(testing_data[\"Race = Caucasian\"] == 1) & (testing_data[\"recidivism_outcome\"] == 1)]\n","\n","print(\"All defendants positive rate:\", round(len(actual_reoffend_all) / len(testing_data), 4))\n","print(\"Black defendants positive rate:\", round(len(actual_reoffend_black) / len(testing_data.loc[testing_data[\"Race = African American\"] == 1]), 4))\n","print(\"White defendants positive rate:\", round(len(actual_reoffend_white) / len(testing_data.loc[testing_data[\"Race = Caucasian\"] == 1]),4))\n"]},{"cell_type":"markdown","metadata":{},"source":["This shows that the algorithm does not satisfy the demographic balance principle, since even though that the the predicted to reoffend rate for Black defendant roughly equals the recidivism rate for Black defendants, the predicted to reoffend rate  (30%) for white defendant is much lower than the actual recidivism rate (38.7%) for white defendants. Black defendants' predicted rate roughly being the same as the actual positice rate is not enough to call an algorithm fair for all demographics.\n","\n","Based on these measurements and data, I would not trust this algorithm to be deployed on its own and with no human judgement, because it for sure violates two out of the the three core principles of algorithmic fairness (violates predictive equality and statistical parity), and we have not calculated calibration, which is a measurement that might be necessary to decide if an algorithm is fair. However, I do think that algorithms can help with aiding humans on their decision."]},{"cell_type":"markdown","metadata":{},"source":["## Problem 3: Predicting Recidivism with Your Own Model (15 points)"]},{"cell_type":"markdown","metadata":{"id":"34MZU8ry7Oqf"},"source":["Now you will train your own model to predict recidivism."]},{"cell_type":"markdown","metadata":{"id":"qRz8dgHT7Oqf"},"source":["3a. Train a model of your choice. You can choose any input features that should be used as well as any pre-processing technique. You are welcome to use models which are not logistic regression models, but if you want to use logistic regression, that's also fine! (2 points)"]},{"cell_type":"markdown","metadata":{},"source":["I first started looking into a premade library in hopes that there's a premade model that accounts for sensitive data and weights different defendant's actions a bit differently to balance the outcomes out with regards to false positive rate and false negative rate. During my search, I found this premade model called fairlearn, and here were the results:"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): \\ WARNING conda.models.version:get_matcher(538): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n","done\n","Solving environment: done\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 4.14.0\n","  latest version: 23.11.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c conda-forge conda\n","\n","\n","\n","# All requested packages already installed.\n","\n","Retrieving notices: ...working... done\n"]}],"source":["!conda install -c conda-forge fairlearn\n","\n","# comment out previous line and run the following line if you are using pip\n","#!pip install fairlearn"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds\n","from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cTCSYvXV7Oqf"},"outputs":[],"source":["# specify training/testing input/output features\n","train_input_features = training_data.drop(columns=\"recidivism_outcome\")\n","train_output_feature = training_data[\"recidivism_outcome\"]\n","test_input_features = testing_data.drop(columns=\"recidivism_outcome\")\n","test_output_feature = testing_data[\"recidivism_outcome\"]\n","\n","#'Race = Other','Race = Asian','Race = Native American','Race = Caucasian','Race = Hispanic','Race = African American'\n","# select sensitive features - in this case I chose race to be the selective feature\n","selected_sensitive_features_train = train_input_features[['Race = Other','Race = Asian','Race = Native American','Race = Caucasian','Race = Hispanic','Race = African American']]\n","selected_sensitive_features_test = test_input_features[['Race = Other','Race = Asian','Race = Native American','Race = Caucasian','Race = Hispanic','Race = African American']]\n","\n","# train a gradient boosting classifier on the training data:\n","model = GradientBoostingClassifier()\n","model.fit(train_input_features, train_output_feature)\n","\n","# specify the constraints (what kind of fairness) we would like to achieve - in this case it'd demographic parity:\n","constraints = DemographicParity()\n","# ExponentiatedGradient is used to create a fair model by optimizing the base model's parameters to satisfy the fairness constraints.\n","fair_model = ExponentiatedGradient(model, constraints=constraints)\n","fair_model.fit(train_input_features, train_output_feature, sensitive_features=selected_sensitive_features_train)\n","\n","# Output predictions and fairness metrics\n","predictions = fair_model.predict(test_input_features)\n","dp_difference = demographic_parity_difference(y_true=test_output_feature, y_pred=predictions, sensitive_features=selected_sensitive_features_test)\n","eod_difference = equalized_odds_difference(y_true=test_output_feature, y_pred=predictions, sensitive_features=selected_sensitive_features_test)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.35714285714285715\n","0.5\n"]}],"source":["print(dp_difference)\n","print(eod_difference)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants metrics:\n","Accuracy: 0.689\n","False Positive Rate: 0.2304\n","False Negative Rate: 0.411\n","Predicted Positive Rate: 0.3905\n","\n","Black defendants metrics:\n","Accuracy: 0.675\n","False Positive Rate: 0.2275\n","False Negative Rate: 0.4183\n","Predicted Positive Rate: 0.4084\n","\n","White defendants metrics:\n","Accuracy: 0.7155\n","False Positive Rate: 0.2321\n","False Negative Rate: 0.3675\n","Predicted Positive Rate: 0.3871\n","\n","Hispanic defendants metrics:\n","Accuracy: 0.7552\n","False Positive Rate: 0.2114\n","False Negative Rate: 0.3043\n","Predicted Positive Rate: 0.3854\n","\n","Asian defendants metrics:\n","Accuracy: 0.4286\n","False Positive Rate: 0.6667\n","False Negative Rate: 0.0\n","Predicted Positive Rate: 0.7143\n","\n","Native American defendants metrics:\n","Accuracy: 0.3333\n","False Positive Rate: 0.5\n","False Negative Rate: 0.75\n","Predicted Positive Rate: 0.3333\n","\n","Other defendants metrics:\n","Accuracy: 0.7456\n","False Positive Rate: 0.2432\n","False Negative Rate: 0.275\n","Predicted Positive Rate: 0.4123\n","\n"]}],"source":["def get_metrics(predictions, actual):\n","    accuracy = round((predictions == actual).mean(), 4)\n","    \n","    false_positives = ((predictions == 1) & (actual == 0)).sum()\n","    total_negatives = (actual == 0).sum()\n","    false_positive_rate = round(false_positives / total_negatives, 4)\n","    \n","    false_negatives = ((predictions == 0) & (actual == 1)).sum()\n","    total_positives = (actual == 1).sum()\n","    false_negative_rate = round(false_negatives / total_positives, 4)\n","    \n","    tp = ((predictions == 1) & (actual == 1)).sum()\n","    fp = ((predictions == 1) & (actual == 0)).sum()\n","    tn = ((predictions == 0) & (actual == 0)).sum()\n","    fn = ((predictions == 0) & (actual == 1)).sum()\n","\n","    predicted_positive_rate = round((tp + fp) / (tp + fn + fp + tn), 4)\n","    \n","    return accuracy, false_positive_rate, false_negative_rate, predicted_positive_rate\n","\n","def print_metrics(model, data, actual, label):\n","    predictions = model.predict(data.drop(columns=['recidivism_outcome']))\n","    accuracy, fpr, fnr, ppr = get_metrics(predictions, actual)\n","    \n","    print(f\"{label} defendants metrics:\")\n","    print(f\"Accuracy: {accuracy}\")\n","    print(f\"False Positive Rate: {fpr}\")\n","    print(f\"False Negative Rate: {fnr}\")\n","    print(f\"Predicted Positive Rate: {ppr}\")\n","    print()\n","\n","# Test performance\n","print_metrics(fair_model, testing_data, testing_data[\"recidivism_outcome\"], \"All\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = African American\"] == 1], testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"], \"Black\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1], testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"], \"White\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = Hispanic\"] == 1], testing_data.loc[testing_data[\"Race = Hispanic\"] == 1][\"recidivism_outcome\"], \"Hispanic\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = Asian\"] == 1], testing_data.loc[testing_data[\"Race = Asian\"] == 1][\"recidivism_outcome\"], \"Asian\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = Native American\"] == 1], testing_data.loc[testing_data[\"Race = Native American\"] == 1][\"recidivism_outcome\"], \"Native American\")\n","print_metrics(fair_model, testing_data.loc[testing_data[\"Race = Other\"] == 1], testing_data.loc[testing_data[\"Race = Other\"] == 1][\"recidivism_outcome\"], \"Other\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Initially, I got really excited, since the accuracy, false positive rate, false negative rate, predicted rates seemed to be much closer for Black and white defendants (about 5% difference compared to 13% initally for false positive rates, and similar differences for the rest), and it almost matched the average defendant's data as well, but that confused me why the Equalized Odds are so bad then, so I wanted to see how the model works on other demographics.\n","\n","It turned out this model did worse on Asian and Native American defendants. Asian defendants had a similar accuracy rates, but a higher false positive rate (0.33) and a much lower (0.0!!!) false negative rate. Native American defendants, however had a lower accuracy rate and a 1.0 (!!!) false positive rate. This made me think that it's possible that there are not many Native American and/or Asian defendants in the dataset, so I wanted to see how many there are, since a difference like this (1.0 compared to 0.22) is shocking and would immediatley disqualify it from being a fair algorithm. To see this, I printed how many Asian and Native American defendants there are, along with the recidivism_outcome for each defendant:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Native American defendant: 6\n","Native American defendants' recidivism_outcome\n","Recidivism outcome: 1 vs predicted: 1\n","Recidivism outcome: 0 vs predicted: 0\n","Recidivism outcome: 1 vs predicted: 0\n","Recidivism outcome: 1 vs predicted: 0\n","Recidivism outcome: 1 vs predicted: 1\n","Recidivism outcome: 0 vs predicted: 0\n","\n","Number of Asian defendant: 7\n","Asian defendants' recidivism_outcome\n","recidivism_outcome: 0 vs predicted: 0\n","recidivism_outcome: 0 vs predicted: 1\n","recidivism_outcome: 1 vs predicted: 1\n","recidivism_outcome: 0 vs predicted: 0\n","recidivism_outcome: 0 vs predicted: 0\n","recidivism_outcome: 0 vs predicted: 0\n","recidivism_outcome: 0 vs predicted: 0\n"]}],"source":["\n","def print_actual(model, data, actual, label):\n","    predictions = model.predict(data.drop(columns=['recidivism_outcome']))\n","    return predictions\n","\n","predicted_asian = print_actual(fair_model, testing_data.loc[testing_data[\"Race = Asian\"] == 1], testing_data.loc[testing_data[\"Race = Asian\"] == 1][\"recidivism_outcome\"], \"Asian\")\n","predicted_native_american = print_actual(fair_model, testing_data.loc[testing_data[\"Race = Native American\"] == 1], testing_data.loc[testing_data[\"Race = Native American\"] == 1][\"recidivism_outcome\"], \"Native American\")\n","\n","native_american_defendants_train = train_output_feature[train_input_features['Race = Native American'] == 1]\n","# print recidivism_outcome for Native American defendants:\n","print(\"Number of Native American defendant: \" + str(len(native_american_defendants_train)))\n","\n","print(\"Native American defendants' recidivism_outcome\")\n","i  = 0\n","for outcome in native_american_defendants_train:\n","  print(\"Recidivism outcome: \" + str(outcome) + \" vs predicted: \" + str(predicted_native_american[i]))\n","  i += 1\n","\n","print()\n","\n","asian_defendants_train = train_output_feature[train_input_features['Race = Asian'] == 1]\n","print(\"Number of Asian defendant: \" + str(len(asian_defendants_train)))\n","print(\"Asian defendants' recidivism_outcome\")\n","# print recidivism_outcome for Native American defendants:\n","j = 0\n","for outcome in asian_defendants_train:\n","  print(\"recidivism_outcome: \" + str(outcome)+ \" vs predicted: \" + str(predicted_asian[j]))\n","  j += 1\n"]},{"cell_type":"markdown","metadata":{},"source":["Seeing this I realized that the shocking prediction accuracy rates come from the problem that there is not enough training data on certain demographics. To fix this, I realized that maybe I should try to train the model based on Equalized Odds:"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# train a gradient boosting classifier on the training data:\n","model_2 = GradientBoostingClassifier()\n","model_2.fit(train_input_features, train_output_feature)\n","\n","# specify the constraints (what kind of fairness) we would like to achieve - in this case it'd demographic parity:\n","constraints_2 = EqualizedOdds()\n","# ExponentiatedGradient is used to create a fair model by optimizing the base model's parameters to satisfy the fairness constraints.\n","fair_model_2 = ExponentiatedGradient(model, constraints=constraints_2)\n","fair_model_2.fit(train_input_features, train_output_feature, sensitive_features=selected_sensitive_features_train)\n","\n","# Output predictions and fairness metrics\n","predictions_2 = fair_model_2.predict(test_input_features)\n","dp_difference_2 = demographic_parity_difference(y_true=test_output_feature, y_pred=predictions, sensitive_features=selected_sensitive_features_test)\n","eod_difference_2 = equalized_odds_difference(y_true=test_output_feature, y_pred=predictions, sensitive_features=selected_sensitive_features_test)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants metrics:\n","Accuracy: 0.6909\n","False Positive Rate: 0.2429\n","False Negative Rate: 0.3913\n","Predicted Positive Rate: 0.4062\n","\n","Black defendants metrics:\n","Accuracy: 0.6858\n","False Positive Rate: 0.2514\n","False Negative Rate: 0.3743\n","Predicted Positive Rate: 0.4425\n","\n","White defendants metrics:\n","Accuracy: 0.7045\n","False Positive Rate: 0.2411\n","False Negative Rate: 0.3816\n","Predicted Positive Rate: 0.3871\n","\n","Hispanic defendants metrics:\n","Accuracy: 0.6927\n","False Positive Rate: 0.2683\n","False Negative Rate: 0.3768\n","Predicted Positive Rate: 0.3958\n","\n","Asian defendants metrics:\n","Accuracy: 0.8571\n","False Positive Rate: 0.1667\n","False Negative Rate: 0.0\n","Predicted Positive Rate: 0.2857\n","\n","Native American defendants metrics:\n","Accuracy: 0.8333\n","False Positive Rate: 0.5\n","False Negative Rate: 0.0\n","Predicted Positive Rate: 0.8333\n","\n","Other defendants metrics:\n","Accuracy: 0.6754\n","False Positive Rate: 0.2432\n","False Negative Rate: 0.475\n","Predicted Positive Rate: 0.3421\n","\n"]}],"source":["# Test performance\n","print_metrics(fair_model_2, testing_data, testing_data[\"recidivism_outcome\"], \"All\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = African American\"] == 1], testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"], \"Black\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1], testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"], \"White\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Hispanic\"] == 1], testing_data.loc[testing_data[\"Race = Hispanic\"] == 1][\"recidivism_outcome\"], \"Hispanic\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Asian\"] == 1], testing_data.loc[testing_data[\"Race = Asian\"] == 1][\"recidivism_outcome\"], \"Asian\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Native American\"] == 1], testing_data.loc[testing_data[\"Race = Native American\"] == 1][\"recidivism_outcome\"], \"Native American\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Other\"] == 1], testing_data.loc[testing_data[\"Race = Other\"] == 1][\"recidivism_outcome\"], \"Other\")\n"]},{"cell_type":"markdown","metadata":{},"source":["The issue of Native American and Asian defendants having highly different outcomes still stood, but since this likely stems from not having enough training data of these demographics, I thought it might be good to either modify the training data by either getting more Native American and Asian defendants, or use the average defendants (across all demographics) + their own demographics data to train it. However, since this homework focuses on Black vs white defendants, I decided to just exclude Native American and Asian for the data analysis, since there were just simply not enough defendants to get representative numbers on their outcomes. "]},{"cell_type":"markdown","metadata":{},"source":["3b. Report the model's performance on (i) all, (ii) white, and (iii) Black defendants, using whatever metrics you believe are appropriate (at least 2). You are also welcome to evaluate performance on other sensitive/protected groups. (4 points)"]},{"cell_type":"markdown","metadata":{},"source":["Based on the previou model, the best results are from model 2, with the following scores:"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants metrics:\n","Accuracy: 0.6918\n","False Positive Rate: 0.2471\n","False Negative Rate: 0.3841\n","Predicted Positive Rate: 0.4117\n","\n","Black defendants metrics:\n","Accuracy: 0.6795\n","False Positive Rate: 0.2606\n","False Negative Rate: 0.3779\n","Predicted Positive Rate: 0.4452\n","\n","White defendants metrics:\n","Accuracy: 0.7073\n","False Positive Rate: 0.25\n","False Negative Rate: 0.3604\n","Predicted Positive Rate: 0.4008\n","\n"]}],"source":["# Test performance\n","print_metrics(fair_model_2, testing_data, testing_data[\"recidivism_outcome\"], \"All\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = African American\"] == 1], testing_data.loc[testing_data[\"Race = African American\"] == 1][\"recidivism_outcome\"], \"Black\")\n","print_metrics(fair_model_2, testing_data.loc[testing_data[\"Race = Caucasian\"] == 1], testing_data.loc[testing_data[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"], \"White\")"]},{"cell_type":"markdown","metadata":{},"source":["Based on the false positive rates and false negative rates, it seems like this model does a fairly good job (or at least definitely better than the first model), making the equalized odds fairness test much better. The FPR is only about 1% more for Black defendants (compared to the 17% difference with the first model). The FNR has gone down to a 2% difference, with Black defendants being classified as falsely negative more than white defendants. The first model had a ~19% difference bewteen Black and white defendants' predictions, with white defendants much more likley to be classified as negative when they actually ended up reoffending. Therefore the equalized odds (otherwise known as Predictive equality) for this model is much better than previously. \n","\n","The statistical parity for this model is also better than previously, but still not perfect, since Black defendants still have a higher (44.6%) chance of being classified positive compared to white defendants (40%), but this is only about a 4.4% difference, while the first measure model classified Black defendants positive 52% of the time, while white defendants at only 30% of the time (which means that Black defendants were 1.7x more likely to be classified as positive).\n","\n","This model, however, still does not satisfy the demographic balance principle, since since the predicted positive rate for Black defendants (44.6%) does not equal the recidivism rate for Black defendants (51%), and the predicted positive rate for white defendants (40.22%) does not equal the recidivism rate for white defendants (38.7%), although the predicted rate got much closer to the actual rate compared to the first model. \n","\n","To check if this model is well-calibrated, we can write the following code:"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All defendants positive rate: 0.4464\n"]}],"source":["actual_reoffend_all = testing_data.loc[testing_data[\"recidivism_outcome\"] == 1]\n","print(\"All defendants positive rate:\", round(len(actual_reoffend_all) / len(testing_data), 4))\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["import random\n","\n","juvie_felony = [\"1000\", \"0100\", \"0010\", \"0001\"]\n","juvie_misdem = [\"1000\", \"0100\", \"0010\", \"0001\"]\n","juvie_other = [\"1000\", \"0100\", \"0010\", \"0001\"]\n","prior_conv = [\"1000\", \"0100\", \"0010\", \"0001\"]\n","degree = [\"10\", \"01\"]\n","disc = [\"100000000000\", \"010000000000\", \"001000000000\", \"000100000000\", \"000010000000\", \"000001000000\", \"000000100000\", \"000000010000\", \"000000001000\", \"000000000100\", \"000000000010\", \"000000000001\"]\n","age = [\"100\", \"010\", \"001\"]\n","gender =  [\"10\", \"01\"]\n","race = [\"000100\", \"000001\"]\n","outcome = [\"0\", \"1\"]\n","\n","items = [juvie_felony, juvie_misdem, juvie_other, prior_conv, degree, disc, age, gender, race, outcome]\n","\n","lst_of_random_test = []\n","for i in range(100):\n","  random_outcome_white = \"\"\n","  random_outcome_black = \"\"\n","  for item in items:\n","    if item != \"race\":\n","      new = str(random.choice(item))\n","      random_outcome_white += new\n","      random_outcome_black += new\n","      \n","    else:\n","      white = \"000100\"\n","      black = \"000001\"\n","      random_outcome_white += white\n","      random_outcome_black += black\n","\n","  lst_of_random_test.append(random_outcome_white)\n","  lst_of_random_test.append(random_outcome_black)\n","\n","def parse_string_to_list(input_string):\n","    return [int(char) for char in input_string]\n","\n","result_list_test = []\n","\n","for random_str in lst_of_random_test:\n","  result_list_test.append(parse_string_to_list(random_str))\n","\n","outcome_lst_test = []\n","test_lst_test = []\n","for rnd in result_list_test:\n","   outcome_lst_test.append(rnd[:-1])\n","   test_lst_test.append(rnd[-1])\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import csv\n","\n","test = open('test.csv', 'w')\n","writer_test = csv.writer(test)\n","\n","\n","row = [\"Juvenile felony count = 0\",\"Juvenile felony count = 1\",\"Juvenile felony count = 2\",\"Juvenile felony count >= 3\",\"Juvenile misdemeanor count = 0\",\"Juvenile misdemeanor count = 1\",\"Juvenile misdemeanor count = 2\",\"Juvenile misdemeanor count >= 3\",\"Juvenile other offense count = 0\",\"Juvenile other offense count = 1\",\"Juvenile other offense count = 2\",\"Juvenile other offense count >= 3\",\"Prior conviction count = 0\",\"Prior conviction count = 1\",\"Prior conviction count = 2\",\"Prior conviction count >= 3\",\"Charge degree = felony\",\"Charge degree = misdemeanor\",\"Charge description = no charge\",\"Charge description = license issue\",\"Charge description = public disturbance\",\"Charge description = negligence\",\"Charge description = drug related\",\"Charge description = alcohol related\",\"Charge description = weapons related\",\"Charge description = evading arrest\",\"Charge description = nonviolent harm\",\"Charge description = theft/fraud/burglary\",\"Charge description = lewdness/prostitution\",\"Charge description = violent crime\",\"Age < 25\",\"Age >= 25 and <=45\",\"Age > 45\",\"Gender = Female\",\"Gender = Male\",\"Race = Other\",\"Race = Asian\",\"Race = Native American\",\"Race = Caucasian\",\"Race = Hispanic\",\"Race = African American\",\"recidivism_outcome\"]\n","writer_test.writerow(row)\n","\n","for row_i in result_list_test:\n","  writer_test.writerow(row_i)\n","\n","test.close()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["test_data_last = pd.read_csv('test.csv')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Black defendants metrics:\n","Accuracy: 0.4914\n","False Positive Rate: 0.431\n","False Negative Rate: 0.5862\n","Predicted Positive Rate: 0.4224\n","\n","White defendants metrics:\n","Accuracy: 0.5833\n","False Positive Rate: 0.5\n","False Negative Rate: 0.3158\n","Predicted Positive Rate: 0.5833\n","\n"]}],"source":["\n","print_metrics(fair_model_2, test_data_last.loc[test_data_last[\"Race = African American\"] == 1], test_data_last.loc[test_data_last[\"Race = African American\"] == 1][\"recidivism_outcome\"], \"Black\")\n","print_metrics(fair_model_2, test_data_last.loc[test_data_last[\"Race = Caucasian\"] == 1], test_data_last.loc[test_data_last[\"Race = Caucasian\"] == 1][\"recidivism_outcome\"], \"White\")"]},{"cell_type":"markdown","metadata":{},"source":["This model gives us the following output:\n","\n","Black defendants metrics:\n","Accuracy: 0.4914\n","False Positive Rate: 0.431\n","False Negative Rate: 0.5862\n","Predicted Positive Rate: 0.4224\n","\n","White defendants metrics:\n","Accuracy: 0.5833\n","False Positive Rate: 0.5\n","False Negative Rate: 0.3158\n","Predicted Positive Rate: 0.5833\n","\n","Which shows us that this model is clearly not calibrated, since the model did not output the same results for the same inputs for Black and white defendants. "]},{"cell_type":"markdown","metadata":{"id":"Qx-2bXR97Oqg"},"source":["3c. Write two paragraphs defending your model design choices, and explaining why you designed the model the way you did. Refer to results from 3b to provide evidence. You're welcome to write two paragraphs explaining why you don't think models should be used in criminal risk prediction at all - this is a reasonable perspective! - but you still need to provide quantitative or non-quantitative evidence to back up your claims. (9 points)"]},{"cell_type":"markdown","metadata":{},"source":["Designing this final model for criminal risk prediction, I decided to address issues of equalized odds and statistical parity. Although the model's output metrics for Black and white defendants, such as accuracy, false positive rate, false negative rate, and predicted positive rate seemed to show that it almost reached equalized odd and statistical parity, it clearly lacked  calibration. We know that it does not meet the requirement to be well calibrated, since the same inputs give different results for people in different demographic groups. I attempted various modifications, including excluding race, age, gender, and juvenile data from the training set, but these adjustments did not significantly improve the model's performance. Instead, removing these variables resulted in an accuracy barely surpassing random guessing, emphasizing the complexity of achieving fairness without compromising predictive accuracy.\n","\n","Even after trying to get my model to satisfy the equalized odds by using a built in library made by developers specifically for this method, I would not trust it to be used criminal risk prediciton, since some demographic groups are severly underrepresented (Indigenous and Asian defendants) so their results were heavily biased against them. This poses ethical concerns, as excluding certain demographics from the model undermines its applicability and fairness.\n","\n","Additionally, in class we discussed that calibration, or equalized odds alone is insufficient for a fair algorithm. While calibration ensures consistent results for the same input across demographic groups, achieving equalized odds becomes challenging without either perfect prediction or calibration, and vice versa, as highlighted in studies by Kleinberg, Mullainathan, Raghavan and Chouldechova (2016). The limitations of the model mean that there are too many challenges and ethical considerations to use them in high-stakes situations like criminal risk prediction."]},{"cell_type":"markdown","metadata":{"id":"LZIGLBkz7Uqh"},"source":["# Sources cited\n","\n","Please cite any sources used to complete this homework in the markdown cell below. Nobody remembers everything, and it's always a good idea to use documentation and online resources to ensure you're growing your skills.\n","\n","Note that copying text from generative AI technology, such as ChatGPT, will be considered plagiarism (and hence result in a 0 grade on this submission). You are allowed to use ChatGPT as a general educational resource (the same way you would a webpage, without copying from it). But if you used ChatGPT as an educational resource, you must include (a) your prompts, (b) ChatGPT's responses, and (c) your validation of why ChatGPT's response is correct; simply noting that the code makes sense does not suffice as an explanation."]},{"cell_type":"markdown","metadata":{"id":"OgQDBLKO8LK3"},"source":["**SOURCES USED:**"]},{"cell_type":"markdown","metadata":{},"source":["Reading in a CSV file: https://stackoverflow.com/questions/58185487/how-to-read-csv-file-into-jupyter-notebook#61956061\n"]},{"cell_type":"markdown","metadata":{},"source":["Selecting rows with certain values: https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values"]},{"cell_type":"markdown","metadata":{},"source":["Selecting columns for training: https://stackoverflow.com/questions/20230326/retrieve-dataframe-of-all-but-one-specified-column\n"]},{"cell_type":"markdown","metadata":{},"source":["Confusion matrix: https://blog.nillsf.com/index.php/2020/05/23/confusion-matrix-accuracy-recall-precision-false-positive-rate-and-f-scores-explained/"]},{"cell_type":"markdown","metadata":{},"source":["Fairlearn documentation: https://fairlearn.org/v0.10/user_guide/fairness_in_machine_learning.html#group-fairness-sensitive-features"]},{"cell_type":"markdown","metadata":{},"source":["Write to CSV file: https://www.pythontutorial.net/python-basics/python-write-csv-file/"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
